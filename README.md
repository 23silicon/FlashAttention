# FlashAttention
Implementing FlashAttention algorithm in CUDA, the basis for modern transformers. 
